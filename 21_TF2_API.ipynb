{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cd12d2a",
   "metadata": {},
   "source": [
    "# 21. TF2 API 개요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed830aeb",
   "metadata": {},
   "source": [
    "## 21-1. TensorFlow2 API로 모델 구성하기\n",
    "### TensorFlow2 API 알아보기\n",
    "#### 1) TensorFlow2 Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b40c5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "\n",
    "# model = keras.Sequential()\n",
    "# model.add(__넣고싶은 레이어__)\n",
    "# model.add(__넣고싶은 레이어__)\n",
    "# model.add(__넣고싶은 레이어__)\n",
    "\n",
    "# model.fit(x, y, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefde155",
   "metadata": {},
   "source": [
    "`model = keras.Sequential()` <br/>\n",
    "- Sequential 모델은 입력 1가지, 출력 1가지를 전제로 함.\n",
    "- sequential하게 차곡차곡 add해서 쌓아 간다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7896c0",
   "metadata": {},
   "source": [
    "#### 2) TensorFlow2 Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b2fc448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "\n",
    "# inputs = keras.Input(shape=(__원하는 입력값 모양__))\n",
    "# x = keras.layers.__넣고싶은 레이어__(관련 파라미터)(input)\n",
    "# x = keras.layers.__넣고싶은 레이어__(관련 파라미터)(x)\n",
    "# outputs = keras.layers.__넣고싶은 레이어__(관련 파라미터)(x)\n",
    "\n",
    "# model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "# model.fit(x, y, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cdf713",
   "metadata": {},
   "source": [
    "`keras.Model`\n",
    "- `Sequential Model`보다 일반적 \n",
    "- `Sequential Model`은 이 `keras.Model`을 상속받은 사례일 뿐 <br/>\n",
    "\n",
    "`Funtional`\n",
    ": 입력과 출력을 규정함으로써 모델 전체를 규정한다는 뜻 (함수형으로 모델 구성하기) <br/>\n",
    "\n",
    "`Input`과 Output을 규정하면 Model이 `inputs`와 `outputs`만으로 규정이 된다. <br/>\n",
    "\n",
    "- Sequential Model과 다르게 `Functial API`를 통해 다중 입력/출력을 가지는 모델을 구성할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0c1aae",
   "metadata": {},
   "source": [
    "#### 3) TensorFlow2 Subclassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7e4f841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "\n",
    "# class CustomModel(keras.Model):\n",
    "#     def __init__(self):\n",
    "#         super(CustomModel, self).__init__()\n",
    "#         self.__정의하고자 하는 레이어__()\n",
    "#         self.__정의하고자 하는 레이어__()\n",
    "#         self.__정의하고자 하는 레이어__()\n",
    "        \n",
    "#     def call(self, ):\n",
    "#         x = self.__정의하고자 하는 레이어(x)\n",
    "#         x = self.__정의하고자 하는 레이어(x)\n",
    "#         x = self.__정의하고자 하는 레이어(x)\n",
    "        \n",
    "#         return x\n",
    "\n",
    "# model = CustomModel()\n",
    "# model.fit(x, y, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56586ff1",
   "metadata": {},
   "source": [
    "`Subclassing`\n",
    "- 제일 자유로운 모델링 진행할 수 있음\n",
    "- `keras.Model`을 상속받은 모델 클래스를 만드는 것 (`Functional`과 다른 점 없음) <br/>\n",
    "\n",
    "`keras.Model`\n",
    "- `__init__()` 메서드 안에서 레이어 간 `forward propagation`을 구현한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d9514f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b686c25",
   "metadata": {},
   "source": [
    "## 21-2. TensorFlow2 API로 모델 작성하기: MNIST (1) Sequential API 활용\n",
    "- 앞서 본 TensorFlow2의 다양한 High-level API를 활용해 이미지 문제를 풀어보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "755e6d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26c9b3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "# 데이터 구성 부분\n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train = x_train[..., np.newaxis]\n",
    "x_test = x_test[..., np.newaxis]\n",
    "\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1eb46b",
   "metadata": {},
   "source": [
    "#### ❓ newaxis\n",
    ": numpy array의 차원을 늘려주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4def9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential Model 구성하기\n",
    "\n",
    "\"\"\"\n",
    "Spec:\n",
    "1. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "2. 64개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "3. Flatten 레이어\n",
    "4. 128개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
    "5. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n",
    "\"\"\"\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a42cdd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 35s 4ms/step - loss: 0.1064 - accuracy: 0.9674\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0329 - accuracy: 0.9895\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0196 - accuracy: 0.9932\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0127 - accuracy: 0.9958\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0092 - accuracy: 0.9968\n",
      "313/313 - 1s - loss: 0.0455 - accuracy: 0.9888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.045518577098846436, 0.9887999892234802]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 설정\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c860aae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efe816a7",
   "metadata": {},
   "source": [
    "## 21-3. TensorFlow2 API로 모델 작성하기: MNIST (2) Functional API 활용\n",
    "- `keras.Model`을 직접 활용해야 하므로 `keras.Input`으로 정의된 input 및 output 레이어 구성을 통해 model을 만들자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8bc2364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcfe3ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train=x_train[...,np.newaxis]\n",
    "x_test=x_test[...,np.newaxis]\n",
    "\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b0d4256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functioanl Model 구성하기\n",
    "\n",
    "\"\"\"\n",
    "Spec:\n",
    "0. (28X28X1) 차원으로 정의된 Input\n",
    "1. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "2. 64개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "3. Flatten 레이어\n",
    "4. 128개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
    "5. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n",
    "\"\"\"\n",
    "\n",
    "inputs = keras.Input(shape=(28, 28, 1))\n",
    "\n",
    "x = keras.layers.Conv2D(32, 3, activation='relu')(inputs)\n",
    "x = keras.layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(128, activation='relu')(x)\n",
    "predictions = keras.layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fba8294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1054 - accuracy: 0.9680\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0357 - accuracy: 0.9887\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0192 - accuracy: 0.9940\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0137 - accuracy: 0.9955\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0096 - accuracy: 0.9969\n",
      "313/313 - 1s - loss: 0.0423 - accuracy: 0.9889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04229588806629181, 0.9889000058174133]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 설정\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd961dc1",
   "metadata": {},
   "source": [
    "Sequential과 Functional은 큰 차이가 없네"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d31dad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a27b636",
   "metadata": {},
   "source": [
    "## 21-4. TensorFlow2 API로 모델 작성하기: MNIST (3) Subclassing 활용\n",
    "- `Subclassing`은 `keras.Model`을 상속받은 클래스를 만드는 것\n",
    "- `__init__()` 메서드 안에서 레이어를 선언하고, `call()` 메서드 안에서 `forward propagation`을 구현하는 방식임\n",
    "- `Functional` 방식과 비교하자면, `call()`의 입력이 Input이고, `call()`의 리턴값이 Output이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e6e5381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96900667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "# 데이터 구성부분\n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train=x_train[...,np.newaxis]\n",
    "x_test=x_test[...,np.newaxis]\n",
    "\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c31e4106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subclassing을 활용한 Model을 구성해주세요.\n",
    "\n",
    "\"\"\"\n",
    "Spec:\n",
    "0. keras.Model 을 상속받았으며, __init__()와 call() 메서드를 가진 모델 클래스\n",
    "1. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "2. 64개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "3. Flatten 레이어\n",
    "4. 128개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
    "5. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n",
    "6. call의 입력값이 모델의 Input, call의 리턴값이 모델의 Output\n",
    "\"\"\"\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(32, 3, activation='relu')\n",
    "        self.conv2 = keras.layers.Conv2D(64, 3, activation='relu')\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.fc1 = keras.layers.Dense(128, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(10, activation='softmax')\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a979486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1062 - accuracy: 0.9680\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0339 - accuracy: 0.9897\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0198 - accuracy: 0.9936\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0126 - accuracy: 0.9960\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0085 - accuracy: 0.9974\n",
      "313/313 - 1s - loss: 0.0458 - accuracy: 0.9880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.045776933431625366, 0.9879999756813049]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 설정\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918e924f",
   "metadata": {},
   "source": [
    "본직적으로 3가지 방법 모두 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8443cf5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e995efce",
   "metadata": {},
   "source": [
    "## 21-5. TensorFlow2 API로 모델 작성 및 학습하기: CIFAR-100 (1) Sequential API 활용\n",
    "https://yeon22.tistory.com/174"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6163bed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73ed4aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "# 데이터 구성 부분\n",
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee8bc6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential Model을 구성해주세요.\n",
    "\"\"\"\n",
    "Spec:\n",
    "1. 16개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "2. pool_size가 2인 MaxPool 레이어\n",
    "3. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "4. pool_size가 2인 MaxPool 레이어\n",
    "5. 256개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
    "6. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n",
    "\"\"\"\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(16, 3, activation='relu'),\n",
    "    keras.layers.MaxPool2D((2, 2)),\n",
    "    keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    keras.layers.MaxPool2D((2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4fcc2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 6s 3ms/step - loss: 3.6078 - accuracy: 0.1578\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.9063 - accuracy: 0.2853\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.5985 - accuracy: 0.3477\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.3795 - accuracy: 0.3905\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.2167 - accuracy: 0.4255\n",
      "313/313 - 1s - loss: 2.6046 - accuracy: 0.3564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.604600191116333, 0.3564000129699707]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 설정\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fb9e79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5078287",
   "metadata": {},
   "source": [
    "## 21-6. TensorFlow2 API로 모델 작성 및 학습하기: CIFAR-100 (2) Functional API 활용\n",
    "- 마찬가지로 keras.Model을 직접 활용해야 하므로 keras.Input으로 정의된 input 및 output 레이어 구성을 통해 model을 구현해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03412882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30f3adf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5977c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functional API를 활용한 Model을 구성해주세요.\n",
    "\"\"\"\n",
    "Spec:\n",
    "0. (32X32X3) 차원으로 정의된 Input\n",
    "1. 16개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "2. pool_size가 2인 MaxPool 레이어\n",
    "3. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "4. pool_size가 2인 MaxPool 레이어\n",
    "5. 256개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
    "6. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n",
    "\"\"\"\n",
    "\n",
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "\n",
    "x = keras.layers.Conv2D(16, 3, activation='relu')(inputs)\n",
    "x = keras.layers.MaxPooling2D((2, 2))(x)\n",
    "x = keras.layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = keras.layers.MaxPooling2D((2, 2))(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(256, activation='relu')(x)\n",
    "predictions = keras.layers.Dense(100, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2ff2016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 3.5822 - accuracy: 0.1637\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.8641 - accuracy: 0.2923\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.5719 - accuracy: 0.3520\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.3637 - accuracy: 0.3952\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.1996 - accuracy: 0.4317\n",
      "313/313 - 1s - loss: 2.5522 - accuracy: 0.3654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.5521655082702637, 0.3653999865055084]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5600702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "124445c7",
   "metadata": {},
   "source": [
    "## 21-8. TensorFlow2 API로 모델 작성 및 학습하기: CIFAR-100 (3) Subclassing 활용\n",
    "- Subclassing은 keras.Model을 상속 받은 클래스를 만드는 것으로 init() 메서드 안에 레이어를 선언하고, call() 메서드 안에 forward propagation을 구현함을 기억하자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b3b6bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74d24a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "# 데이터 구성부분\n",
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23dbb805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subclassing을 활용한 Model을 구성해주세요.\n",
    "\n",
    "\"\"\"\n",
    "Spec:\n",
    "0. keras.Model 을 상속받았으며, __init__()와 call() 메서드를 가진 모델 클래스\n",
    "1. 16개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "2. pool_size가 2인 MaxPool 레이어\n",
    "3. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "4. pool_size가 2인 MaxPool 레이어\n",
    "5. 256개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
    "6. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n",
    "7. call의 입력값이 모델의 Input, call의 리턴값이 모델의 Output\n",
    "\"\"\"\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(16, 3, activation='relu')\n",
    "        self.maxpool1 = keras.layers.MaxPool2D((2, 2))\n",
    "        self.conv2 = keras.layers.Conv2D(32, 3, activation='relu')\n",
    "        self.maxpool2 = keras.layers.MaxPool2D((2, 2))\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.fc1 = keras.layers.Dense(256, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(100, activation='softmax')\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0269bb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 3.6108 - accuracy: 0.1566\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.9220 - accuracy: 0.2793\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.6334 - accuracy: 0.3361\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.4283 - accuracy: 0.3812\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 2.2590 - accuracy: 0.4121\n",
      "313/313 - 1s - loss: 2.5960 - accuracy: 0.3557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.5960018634796143, 0.35569998621940613]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657de49f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f61b111",
   "metadata": {},
   "source": [
    "## 21-8. GradientTape의 활용\n",
    "### Automatic differentiation - GradientTape\n",
    "위 3가지 방법들에서 동일했던 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29884fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델 학습 설정\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss='sparse_categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536c0572",
   "metadata": {},
   "source": [
    "#### 딥러닝의 모델 훈련 과정\n",
    "1. Forward Propagation 수행 및 중간 레이어값 저장\n",
    "2. Loss 값 계산\n",
    "3. 중간 레이어값 및 Loss를 활용한 chain rule 방식의 backward propagation 수행\n",
    "4. 학습 파라미터 업데이트 <br/>\n",
    "\n",
    "- TF2 API에는 `model.fi()`이란 메서드 안에 모두 추상화되어 감추어져 있다.\n",
    "- tensorflow에서 젝오하는 `tf.GradientTape`는 위와 같은 순전파(forward pass)로 진행된 모든 연산의 중간 레이어 값을 `tape`에 기록하고, 이를 이용해 gradient를 계산한 후 `tape`를 폐기함 <br/>\n",
    "\n",
    "아래에선 이전 스텝에서 진행했던 학습을 `tf.GradientTape`을 이용해 변형해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe34ee86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# 데이터 구성부분\n",
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(len(x_train), len(x_test))\n",
    "\n",
    "# 모델 구성부분\n",
    "class CustomModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(16, 3, activation='relu')\n",
    "        self.maxpool1 = keras.layers.MaxPool2D((2,2))\n",
    "        self.conv2 = keras.layers.Conv2D(32, 3, activation='relu')\n",
    "        self.maxpool2 = keras.layers.MaxPool2D((2,2))\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.fc1 = keras.layers.Dense(256, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(100, activation='softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = CustomModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be99a80b",
   "metadata": {},
   "source": [
    "여기까진 앞에서 다룬 Subclassing을 활용한 모델 작성법과 동일하다. <br/>\n",
    "달라지는 부분은 `model.compile()`, `model.fit()`을 통해 손쉽게 진행햇던 학습 세팅 및 수행 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0104af01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델 학습 설정\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss='sparse_categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7374d37f",
   "metadata": {},
   "source": [
    "위와 같은 방식으로 loss, optimizer을 지정해주면 내부적으로 매 스텝 학습이 진행될 때마다 발생하는 loss 및 gradient가 어떻게 학습 파라미터를 업데이트하게 되는지를 지정해주는 작업이 `model.compile()` 안에서 자동으로 진행되었다. <br/> <br/>\n",
    "\n",
    "아래 코드는 `tape.gradient()`를 통해 매스텝 학습이 진행될 때마다 발생하는 그래디언트를 추출한 후 `optimizer.apply_gradients()`를 통해 발생한 그래디언트가 업데이트 해야 할 파라미터 `model.trainable_variables`를 지정해주는 과정을 기술한 것\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20f58262",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# tf.GradientTape()를 활용한 train_step\n",
    "def train_step(features, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(features)\n",
    "        loss = loss_func(labels, predictions)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c9c297",
   "metadata": {},
   "source": [
    "위와 같이 매 스텝 진행되는 학습의 실제 동작이 `train_step()` 메서드로 구현되었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b880b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(x_train, y_train, epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46019015",
   "metadata": {},
   "source": [
    "이 `model.fit()`으로 위와 같이 한 줄로 간단히 수행되던 실제 배치 학습 과정은, 매 스텝마다 위에서 구현했던 `train_step()`가 호출되는 과정으로 바꾸어 구현할 수 있다. <br/>\n",
    "`model.fit()` 호출 시 결정되는 `batch_size`만 이번 스텝에서 결정해주면 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e0203ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: last batch loss = 1.9104\n",
      "Epoch 1: last batch loss = 1.7795\n",
      "Epoch 2: last batch loss = 1.6579\n",
      "Epoch 3: last batch loss = 1.5141\n",
      "Epoch 4: last batch loss = 1.4745\n",
      "It took 85.83051419258118 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def train_model(batch_size=32):\n",
    "    start = time.time()\n",
    "    for epoch in range(5):\n",
    "        x_batch = []\n",
    "        y_batch = []\n",
    "        for step, (x, y) in enumerate(zip(x_train, y_train)):\n",
    "            x_batch.append(x)\n",
    "            y_batch.append(y)\n",
    "            if step % batch_size == batch_size - 1:\n",
    "                loss = train_step(np.array(x_batch, dtype=np.float32), np.array(y_batch, dtype=np.float32))\n",
    "                x_batch = []\n",
    "                y_batch = []\n",
    "        print('Epoch %d: last batch loss = %.4f' % (epoch, float(loss)))\n",
    "    print(\"It took {} seconds\".format(time.time() - start))\n",
    "\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cd6fa2",
   "metadata": {},
   "source": [
    "이렇게 위에서 구현한 `train_model()` 메서드가 실은 우리가 그동안 사용했던 `model.fit()` 메서드와 기능적으로 동일함을 확인할 수 있다. <br/><br/>\n",
    "\n",
    "이렇게 `tf.GradientTape()`를 활용하면 `model.compile()`과 `model.fit()` 안에 감추어져 있던 한 스텝의 학습 단계(위 예제에선 `train_step` 메서드)를 끄집어내 자유롭게 재구성할 수 있다. <br/> <br/>\n",
    "그동안 흔히 다루었던 지도학습 방식과 다른 강화학습 or GAN(Generative Advasarial Network)의 학습을 위해선 `train_step` 메서드의 재구성이 필수적이므로 `tf.GradientTape()`의 활용법을 꼭 숙지해두자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81835ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3452"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "prediction = model.predict(x_test, batch_size=x_test.shape[0], verbose=1)\n",
    "temp = sum(np.squeeze(y_test) == np.argmax(prediction, axis=1))\n",
    "temp / len(y_test) # Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753a0c77",
   "metadata": {},
   "source": [
    "그래디언트를 활용할 필요가 없는 evaluation 단계는 기존 `model.predict()` 메서드를 다시 활용했다. 학습이 충분히 진행되지 않았으므로 최종 Accuracy는 신경쓰지 말자 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60fa6b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
